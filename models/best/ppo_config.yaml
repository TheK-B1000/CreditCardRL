algorithm: PPO
policy: MlpPolicy
total_timesteps: 500000
learning_rate: 0.0003
n_steps: 2048
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01
vf_coef: 0.5
max_grad_norm: 0.5
policy_kwargs:
  net_arch:
    pi:
    - 256
    - 256
    vf:
    - 256
    - 256
seed: 42
env_config: configs/env/default_3card.yaml
n_envs: 4
eval_freq: 10000
eval_episodes: 50
checkpoint_freq: 50000
log_dir: runs/
